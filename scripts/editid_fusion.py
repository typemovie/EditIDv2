#!/usr/bin/env python3
"""
äº¤äº’å¼SafeTensorsæƒé‡èåˆå·¥å…·
å…ˆè¿›è¡Œkeyå¯¹æ¯”åˆ†æï¼Œç„¶åè®©ç”¨æˆ·é€‰æ‹©æ˜¯å¦èåˆä»¥åŠèåˆæ–¹å¼
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, Set
import torch
from safetensors import safe_open
from safetensors.torch import save_file
from datetime import datetime


class InteractiveSafeTensorsMerger:
    """äº¤äº’å¼SafeTensorsæ–‡ä»¶èåˆå™¨"""

    def __init__(self):
        self.file1_tensors = {}
        self.file2_tensors = {}
        self.file1_metadata = {}
        self.file2_metadata = {}
        self.file1_info = {}
        self.file2_info = {}
        self.file1_path = ""
        self.file2_path = ""

    def load_safetensors_info(self, file_path: str) -> Tuple[Dict[str, dict], Dict[str, str]]:
        """åŠ è½½safetensorsæ–‡ä»¶ä¿¡æ¯ï¼ˆåªè·å–keyå’Œshapeä¿¡æ¯ï¼Œä¸åŠ è½½å®é™…æ•°æ®ï¼‰"""
        tensor_info = {}
        metadata = {}

        try:
            with safe_open(file_path, framework="pt", device="cpu") as f:
                # è·å–å…ƒæ•°æ®
                metadata = f.metadata() or {}

                # è·å–æ‰€æœ‰å¼ é‡çš„åŸºæœ¬ä¿¡æ¯
                for key in f.keys():
                    tensor = f.get_tensor(key)
                    tensor_info[key] = {
                        'shape': tensor.shape,
                        'dtype': tensor.dtype,
                        'size': tensor.numel()
                    }

            return tensor_info, metadata

        except Exception as e:
            print(f"âœ— åŠ è½½å¤±è´¥: {file_path}")
            print(f"  é”™è¯¯: {str(e)}")
            raise

    def analyze_compatibility(self, file1_info: Dict[str, dict], file2_info: Dict[str, dict]) -> dict:
        """åˆ†æä¸¤ä¸ªæ–‡ä»¶çš„å…¼å®¹æ€§"""
        keys1 = set(file1_info.keys())
        keys2 = set(file2_info.keys())

        common_keys = keys1.intersection(keys2)
        only_in_file1 = keys1 - keys2
        only_in_file2 = keys2 - keys1

        # åˆ†æç›¸åŒkeyçš„å…¼å®¹æ€§
        compatible_keys = set()
        shape_mismatch_keys = set()
        dtype_mismatch_keys = set()

        for key in common_keys:
            info1 = file1_info[key]
            info2 = file2_info[key]

            if info1['shape'] != info2['shape']:
                shape_mismatch_keys.add(key)
            elif info1['dtype'] != info2['dtype']:
                dtype_mismatch_keys.add(key)
            else:
                compatible_keys.add(key)

        return {
            'keys1': keys1,
            'keys2': keys2,
            'common_keys': common_keys,
            'only_in_file1': only_in_file1,
            'only_in_file2': only_in_file2,
            'compatible_keys': compatible_keys,
            'shape_mismatch_keys': shape_mismatch_keys,
            'dtype_mismatch_keys': dtype_mismatch_keys
        }

    def display_analysis_summary(self, analysis: dict) -> None:
        """æ˜¾ç¤ºåˆ†ææ‘˜è¦"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ“Š æ–‡ä»¶å¯¹æ¯”åˆ†ææ‘˜è¦")
        print(f"{'=' * 60}")

        print(f"ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
        print(f"  æ–‡ä»¶1 keyæ•°é‡: {len(analysis['keys1'])}")
        print(f"  æ–‡ä»¶2 keyæ•°é‡: {len(analysis['keys2'])}")
        print(f"  ç›¸åŒ keyæ•°é‡: {len(analysis['common_keys'])}")
        print(f"  ä»…æ–‡ä»¶1ç‹¬æœ‰: {len(analysis['only_in_file1'])}")
        print(f"  ä»…æ–‡ä»¶2ç‹¬æœ‰: {len(analysis['only_in_file2'])}")

        print(f"\nğŸ” å…¼å®¹æ€§åˆ†æ:")
        print(f"  å®Œå…¨å…¼å®¹: {len(analysis['compatible_keys'])} ä¸ª")
        print(f"  å½¢çŠ¶ä¸åŒ¹é…: {len(analysis['shape_mismatch_keys'])} ä¸ª")
        print(f"  ç±»å‹ä¸åŒ¹é…: {len(analysis['dtype_mismatch_keys'])} ä¸ª")

        # å…¼å®¹æ€§è¯„ä¼°
        total_common = len(analysis['common_keys'])
        if total_common > 0:
            compatibility_rate = len(analysis['compatible_keys']) / total_common * 100
            print(f"  å…¼å®¹ç‡: {compatibility_rate:.1f}%")

            if compatibility_rate >= 95:
                print(f"  âœ… é«˜åº¦å…¼å®¹ï¼Œæ¨èèåˆ")
            elif compatibility_rate >= 80:
                print(f"  âš ï¸  ä¸­ç­‰å…¼å®¹ï¼Œå¯è°¨æ…èåˆ")
            else:
                print(f"  âŒ å…¼å®¹æ€§è¾ƒä½ï¼Œä¸æ¨èèåˆ")

        print(f"{'=' * 60}")

    def display_detailed_analysis(self, analysis: dict) -> None:
        """æ˜¾ç¤ºè¯¦ç»†åˆ†æ"""
        print(f"\nğŸ” è¯¦ç»†Keyåˆ†æ:")

        # æ˜¾ç¤ºå½¢çŠ¶ä¸åŒ¹é…çš„key
        if analysis['shape_mismatch_keys']:
            print(f"\nâš ï¸  å½¢çŠ¶ä¸åŒ¹é…çš„Key ({len(analysis['shape_mismatch_keys'])}ä¸ª):")
            for i, key in enumerate(sorted(analysis['shape_mismatch_keys'])):
                if i >= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    ... è¿˜æœ‰ {len(analysis['shape_mismatch_keys']) - 5} ä¸ª")
                    break
                info1 = self.file1_info[key]
                info2 = self.file2_info[key]
                print(f"    {key}: {info1['shape']} vs {info2['shape']}")

        # æ˜¾ç¤ºç±»å‹ä¸åŒ¹é…çš„key
        if analysis['dtype_mismatch_keys']:
            print(f"\nâš ï¸  ç±»å‹ä¸åŒ¹é…çš„Key ({len(analysis['dtype_mismatch_keys'])}ä¸ª):")
            for i, key in enumerate(sorted(analysis['dtype_mismatch_keys'])):
                if i >= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    ... è¿˜æœ‰ {len(analysis['dtype_mismatch_keys']) - 5} ä¸ª")
                    break
                info1 = self.file1_info[key]
                info2 = self.file2_info[key]
                print(f"    {key}: {info1['dtype']} vs {info2['dtype']}")

        # æ˜¾ç¤ºç‹¬æœ‰çš„key
        if analysis['only_in_file1']:
            print(f"\nğŸ“‹ ä»…åœ¨æ–‡ä»¶1ä¸­çš„Key ({len(analysis['only_in_file1'])}ä¸ª):")
            for i, key in enumerate(sorted(analysis['only_in_file1'])):
                if i >= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    ... è¿˜æœ‰ {len(analysis['only_in_file1']) - 5} ä¸ª")
                    break
                print(f"    {key}")

        if analysis['only_in_file2']:
            print(f"\nğŸ“‹ ä»…åœ¨æ–‡ä»¶2ä¸­çš„Key ({len(analysis['only_in_file2'])}ä¸ª):")
            for i, key in enumerate(sorted(analysis['only_in_file2'])):
                if i >= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    ... è¿˜æœ‰ {len(analysis['only_in_file2']) - 5} ä¸ª")
                    break
                print(f"    {key}")

    def get_user_choice_merge(self) -> bool:
        """è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦è¿›è¡Œèåˆ"""
        print(f"\n{'=' * 60}")
        print("ğŸ¤” æ˜¯å¦è¦è¿›è¡Œæƒé‡èåˆï¼Ÿ")
        print("1. æ˜¯ï¼Œè¿›è¡Œèåˆ")
        print("2. å¦ï¼Œä»…æŸ¥çœ‹åˆ†æç»“æœ")
        print("3. é€€å‡ºç¨‹åº")

        while True:
            choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
            if choice == "1":
                return True
            elif choice == "2":
                return False
            elif choice == "3":
                print("ç¨‹åºé€€å‡º")
                sys.exit(0)
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")

    def get_merge_strategy(self) -> str:
        """é€‰æ‹©èåˆç­–ç•¥"""
        print(f"\nğŸ”§ é€‰æ‹©èåˆç­–ç•¥:")
        print("1. åŠ æƒå¹³å‡ (weighted_average) - æ¨è")
        print("   å…¬å¼: (1-Î±) Ã— æ–‡ä»¶1 + Î± Ã— æ–‡ä»¶2")
        print("2. ç›¸åŠ èåˆ (add)")
        print("   å…¬å¼: æ–‡ä»¶1 + Î± Ã— æ–‡ä»¶2")
        print("3. ç›¸ä¹˜èåˆ (multiply)")
        print("   å…¬å¼: æ–‡ä»¶1 Ã— (1 + Î± Ã— æ–‡ä»¶2)")

        strategies = {
            "1": "weighted_average",
            "2": "add",
            "3": "multiply"
        }

        while True:
            choice = input("\nè¯·é€‰æ‹©èåˆç­–ç•¥ (1/2/3): ").strip()
            if choice in strategies:
                return strategies[choice]
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")

    def get_alpha_value(self, strategy: str) -> float:
        """è·å–èåˆæƒé‡Î±å€¼"""
        print(f"\nâš–ï¸  è®¾ç½®èåˆæƒé‡ Î±:")

        if strategy == "weighted_average":
            print("Î± = 0.0: å®Œå…¨ä½¿ç”¨æ–‡ä»¶1")
            print("Î± = 0.5: æ–‡ä»¶1å’Œæ–‡ä»¶2å„å 50%")
            print("Î± = 1.0: å®Œå…¨ä½¿ç”¨æ–‡ä»¶2")
            print("æ¨èå€¼: 0.3-0.7")
        elif strategy == "add":
            print("Î± æ§åˆ¶æ–‡ä»¶2çš„å½±å“å¼ºåº¦")
            print("æ¨èå€¼: 0.1-0.3")
        elif strategy == "multiply":
            print("Î± æ§åˆ¶æ–‡ä»¶2å¯¹æ–‡ä»¶1çš„è°ƒåˆ¶å¼ºåº¦")
            print("æ¨èå€¼: 0.1-0.5")

        while True:
            try:
                alpha = float(input(f"\nè¯·è¾“å…¥Î±å€¼ (0.0-1.0): ").strip())
                if 0.0 <= alpha <= 1.0:
                    return alpha
                else:
                    print("Î±å€¼å¿…é¡»åœ¨0.0åˆ°1.0ä¹‹é—´")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

    def get_output_path(self, default_path: str) -> str:
        """è·å–è¾“å‡ºè·¯å¾„"""
        print(f"\nğŸ’¾ è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„:")
        print(f"é»˜è®¤è·¯å¾„: {default_path}")

        choice = input("ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼Ÿ(Y/n): ").strip().lower()
        if choice in ['', 'y', 'yes']:
            return default_path

        while True:
            path = input("è¯·è¾“å…¥æ–°çš„è¾“å‡ºè·¯å¾„: ").strip()
            if path:
                # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
                output_dir = os.path.dirname(path)
                if output_dir and not os.path.exists(output_dir):
                    try:
                        os.makedirs(output_dir)
                        print(f"å·²åˆ›å»ºç›®å½•: {output_dir}")
                    except Exception as e:
                        print(f"æ— æ³•åˆ›å»ºç›®å½•: {e}")
                        continue

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(path):
                    overwrite = input(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–ï¼Ÿ(y/N): ").strip().lower()
                    if overwrite not in ['y', 'yes']:
                        continue

                return path

    def load_full_tensors(self, file_path: str) -> Tuple[Dict[str, torch.Tensor], Dict[str, str]]:
        """åŠ è½½å®Œæ•´çš„å¼ é‡æ•°æ®"""
        tensors = {}
        metadata = {}

        print(f"æ­£åœ¨åŠ è½½: {file_path}")
        try:
            with safe_open(file_path, framework="pt", device="cpu") as f:
                metadata = f.metadata() or {}
                for key in f.keys():
                    tensors[key] = f.get_tensor(key)
            print(f"âœ“ åŠ è½½å®Œæˆ: {len(tensors)} ä¸ªå¼ é‡")
            return tensors, metadata
        except Exception as e:
            print(f"âœ— åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def merge_tensors(self, tensors1: Dict[str, torch.Tensor],
                      tensors2: Dict[str, torch.Tensor],
                      alpha: float, strategy: str) -> Dict[str, torch.Tensor]:
        """èåˆå¼ é‡"""
        print(f"\nğŸ”„ å¼€å§‹èåˆ...")
        print(f"ç­–ç•¥: {strategy}, Î± = {alpha}")

        keys1 = set(tensors1.keys())
        keys2 = set(tensors2.keys())
        common_keys = keys1.intersection(keys2)

        merged_tensors = {}
        success_count = 0
        skip_count = 0

        # èåˆç›¸åŒçš„key
        for key in common_keys:
            tensor1 = tensors1[key]
            tensor2 = tensors2[key]

            # æ£€æŸ¥å…¼å®¹æ€§
            if tensor1.shape != tensor2.shape:
                print(f"âš ï¸  è·³è¿‡å½¢çŠ¶ä¸åŒ¹é…çš„key: {key}")
                merged_tensors[key] = tensor1
                skip_count += 1
                continue

            if tensor1.dtype != tensor2.dtype:
                tensor2 = tensor2.to(tensor1.dtype)

            try:
                if strategy == "weighted_average":
                    merged_tensor = (1 - alpha) * tensor1 + alpha * tensor2
                elif strategy == "add":
                    merged_tensor = tensor1 + alpha * tensor2
                elif strategy == "multiply":
                    merged_tensor = tensor1 * (1 + alpha * tensor2)

                merged_tensors[key] = merged_tensor
                success_count += 1

            except Exception as e:
                print(f"âœ— èåˆå¤±è´¥: {key}, ä½¿ç”¨æ–‡ä»¶1çš„å€¼")
                merged_tensors[key] = tensor1
                skip_count += 1

        # æ·»åŠ ç‹¬æœ‰çš„key
        for key in keys1 - keys2:
            merged_tensors[key] = tensors1[key]

        for key in keys2 - keys1:
            merged_tensors[key] = tensors2[key]

        print(f"âœ“ èåˆå®Œæˆ: æˆåŠŸ {success_count}, è·³è¿‡ {skip_count}, æ€»è®¡ {len(merged_tensors)}")
        return merged_tensors

    def save_merged_file(self, merged_tensors: Dict[str, torch.Tensor], output_path: str):
        """ä¿å­˜èåˆåçš„æ–‡ä»¶"""
        print(f"\nğŸ’¾ ä¿å­˜æ–‡ä»¶: {output_path}")

        try:
            # åˆå¹¶å…ƒæ•°æ®
            merged_metadata = {}
            merged_metadata.update(self.file1_metadata)
            for k, v in self.file2_metadata.items():
                if k not in merged_metadata:
                    merged_metadata[k] = v

            # æ·»åŠ èåˆä¿¡æ¯
            merged_metadata["merged_by"] = "InteractiveSafeTensorsMerger"
            merged_metadata["merge_timestamp"] = datetime.now().isoformat()
            merged_metadata["source_file1"] = os.path.basename(self.file1_path)
            merged_metadata["source_file2"] = os.path.basename(self.file2_path)

            save_file(merged_tensors, output_path, metadata=merged_metadata)

            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(output_path) / (1024 * 1024)
            print(f"âœ“ ä¿å­˜æˆåŠŸ!")
            print(f"  æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            print(f"  å¼ é‡æ•°é‡: {len(merged_tensors)}")

        except Exception as e:
            print(f"âœ— ä¿å­˜å¤±è´¥: {str(e)}")
            raise

    def process_files(self, file1_path: str, file2_path: str, default_output_path: str):
        """å¤„ç†æ•´ä¸ªäº¤äº’å¼èåˆæµç¨‹"""
        self.file1_path = file1_path
        self.file2_path = file2_path

        print("=" * 60)
        print("ğŸš€ äº¤äº’å¼SafeTensorsæƒé‡èåˆå·¥å…·")
        print("=" * 60)
        print(f"æ–‡ä»¶1: {file1_path}")
        print(f"æ–‡ä»¶2: {file2_path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file1_path):
            raise FileNotFoundError(f"æ–‡ä»¶1ä¸å­˜åœ¨: {file1_path}")
        if not os.path.exists(file2_path):
            raise FileNotFoundError(f"æ–‡ä»¶2ä¸å­˜åœ¨: {file2_path}")

        # åŠ è½½æ–‡ä»¶ä¿¡æ¯è¿›è¡Œåˆ†æ
        print(f"\nğŸ“Š æ­£åœ¨åˆ†ææ–‡ä»¶...")
        self.file1_info, self.file1_metadata = self.load_safetensors_info(file1_path)
        self.file2_info, self.file2_metadata = self.load_safetensors_info(file2_path)

        # è¿›è¡Œå…¼å®¹æ€§åˆ†æ
        analysis = self.analyze_compatibility(self.file1_info, self.file2_info)

        # æ˜¾ç¤ºåˆ†æç»“æœ
        self.display_analysis_summary(analysis)

        # è¯¢é—®æ˜¯å¦æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
        show_detail = input(f"\nğŸ“‹ æ˜¯å¦æŸ¥çœ‹è¯¦ç»†åˆ†æï¼Ÿ(y/N): ").strip().lower()
        if show_detail in ['y', 'yes']:
            self.display_detailed_analysis(analysis)

        # è¯¢é—®æ˜¯å¦è¿›è¡Œèåˆ
        if not self.get_user_choice_merge():
            print("åˆ†æå®Œæˆï¼Œç¨‹åºç»“æŸã€‚")
            return

        # è·å–èåˆå‚æ•°
        strategy = self.get_merge_strategy()
        alpha = self.get_alpha_value(strategy)
        output_path = self.get_output_path(default_output_path)

        # ç¡®è®¤èåˆå‚æ•°
        print(f"\n{'=' * 60}")
        print("ğŸ“ èåˆå‚æ•°ç¡®è®¤:")
        print(f"  ç­–ç•¥: {strategy}")
        print(f"  æƒé‡Î±: {alpha}")
        print(f"  è¾“å‡º: {output_path}")
        print(f"  é¢„è®¡èåˆkeyæ•°: {len(analysis['compatible_keys'])}")

        confirm = input(f"\nç¡®è®¤å¼€å§‹èåˆï¼Ÿ(Y/n): ").strip().lower()
        if confirm in ['n', 'no']:
            print("æ“ä½œå·²å–æ¶ˆ")
            return

        # åŠ è½½å®Œæ•´å¼ é‡æ•°æ®
        print(f"\nğŸ“¦ åŠ è½½å®Œæ•´æ•°æ®...")
        file1_tensors, _ = self.load_full_tensors(file1_path)
        file2_tensors, _ = self.load_full_tensors(file2_path)

        # æ‰§è¡Œèåˆ
        merged_tensors = self.merge_tensors(file1_tensors, file2_tensors, alpha, strategy)

        # ä¿å­˜ç»“æœ
        self.save_merged_file(merged_tensors, output_path)

        print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="äº¤äº’å¼SafeTensorsæƒé‡èåˆå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python interactive_safetensors_merger.py
  python interactive_safetensors_merger.py --file1 model1.safetensors --file2 model2.safetensors
        """
    )

    parser.add_argument("--file1",
                        default="/dev_share/gdli7/models/pulid/editid_v2_insert_512_5000_id_loss.safetensors",
                        help="ç¬¬ä¸€ä¸ªsafetensorsæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--file2",
                        default="/dev_share/gdli7/models/pulid/editid_v2_insert_512_5000_id_loss_05_10.safetensors",
                        help="ç¬¬äºŒä¸ªsafetensorsæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output",
                        default="/dev_share/gdli7/models/pulid/editid_v2_insert_512_5000_id_loss_05_10_update.safetensors",
                        help="é»˜è®¤è¾“å‡ºè·¯å¾„")

    args = parser.parse_args()

    try:
        merger = InteractiveSafeTensorsMerger()
        merger.process_files(args.file1, args.file2, args.output)
    except KeyboardInterrupt:
        print(f"\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"âœ— å¤„ç†å¤±è´¥: {str(e)}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())